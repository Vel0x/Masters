\chapter{Background and Related Work}\label{background}




\section{Previous Work}\label{background_previous_work}

    %Talk about everything. Even the stuff I didn't use
    %The AP data from Arsham

    In the first year of this project much of the initial research was done. In this section some of the key topics will be briefly discussed.

    \input{Background/AirQuality}

    \subsection{Geostatistical Mapping}
    
        It was discovered that when working with an actual data set, obtained by using a sensor built by a previous years student, \emph{Eric Staples}, work would have to be performed in order to interpolate the data effectively. Generally, heat maps are used to show various concentrations and levels of variables in a two dimensional environment and so the same would be used in this project. The interpolation method was a more difficult question. Initial research suggested that some sort of convolution filter, or blur, when applied to a sufficiently dense data set would give a reasonable approximation, however this was later found to be incorrect. Further research showed that when interpolating environmental data such as pollutant levels, the most common method is kriging, a statistical method which fits a curve to the data set. Kriging is used as the basis in many advanced models. 

    \subsection{Compressive Sampling}

        Compressive sampling was looked into briefly as a method of enhancing our data collection methodology. The basis behind compressive sampling is that more measurements are taken in areas of high variance, with less measurements taken in areas of lower variance. Essentially this is a variable method of conforming to the Nyquist theorem. The work on this area was discovered to involve much background research into the nature of the pollutants and the areas they build up. It would not work if there were to be a change in the environment. As such this technique was not used in the final solution.

    \subsection{Sensor Creation}

        Initially this project was intended to have a practical component, however due to a more advanced group within the university already working with Lothian Buses, preference was given to their project. Before this change, research was done into building a physical sensor using cheap, off the shelf parts, which would be dynamically calibrated using the techniques discussed in the OpenSense project paper \cite{ontheflycalibration}. Individual sensors were researched and found, and indeed purchased in order to make a prototype, before cancelling the physical implementation. 
    


\input{Background/BackgroundInterpolationMethods}

\section{Mobile Sensing Models}\label{background_mobile_sensing_models}

\maheshi{Not sure about this section at all. In terms of mobile sensing models I could talk about some of the different experiments that have been done such as CarTel, Cafnet and OpenSense, but I would only be touching upon this again, and stating what they do?}


\section{Wireless Propagation Models}

    \maheshi{Not sure how much to write about this? It is a complex area and if I go into it any further I'd spend the remaining two weeks just reading up on this.}

    When implementing a simulation of wireless communications on of the decisions which must be made is which radio propagation model to use. These propagation models define how different signals behave under different conditions. These functions are generally given in terms of a mathematical equation. Using these models we can enter information about our radio signal, such as frequency, transmitter power and receiver power,  and gain information such as the signal to noise ratio of the signal over some distance.

    In Omnet++, which is the simulator we will use, there are six different models implemented. These models are ``FreeSpaceModel'', ``TwoRayGroundModel'', ``RiceModel'', ``RayleighModel'', ``NakagamiModel'' and ``LogNormalShadowingModel''. The Free Space model is the simplest of these models and acts the same way a signal would in ``free space''. That is to say, a space where there is no interference from external signals, or the original signal through reflection, refraction or diffraction. This model is usually used as a component of other models. 

    The two ray ground model is only slightly more advanced, in that it takes into account a singular reflections from some boundary, usually the ground.

    The log normal shadowing model builds on this again. This model has two variable parameter $\gamma$ and $\sigma$ which are used to tune the model to the environment. These parameters provide information about the types of obstacles they are likely to experience and are generally provided through empirical analysis. 

    Nakagami's distribution is a variation of a gamma distribution in that we provide two parameters to this model, $m$ and $\Omega$, which control the shape of the distribution. In order to achieve a propagation model, this distribution is applied to the power level~\cite{nakagamipowerlevel}.

    The Rice model, also known as the Longley-Rice model, has origins in telecommunications. Originally designed to take into account terrain, it requires up to 11 input parameters~\cite{ricemodel}. This model is complicated, but provides accurate information, and indeed is used by the US Federal Communications Commission~\cite{fcclongleyrice}.

    The final model is the Rayleigh model. This model works by assuming that fading happens according to a random distribution when passing through some material. This model has shown promising results in dense urban environments~\cite{rayleighmanhattan}.




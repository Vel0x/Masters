\chapter{Prediction Evaluation}\label{prediction_evaluation}

	\section{Motivation}\label{prediction_evaluation_motivation}

		In sampling data it is almost inevitable that information will be missed. In order to accurately reconstruct the original data we must take certain precautions. One of these precautions is making sure that we sample at a rate high enough to reconstruct all information. This rate goes by the term \emph{Nyquist rate}~\cite{nyquistrate}. The Nyquist rate is the rate of taking measurements such that the original information can be reconstructed without aliasing occurring. This essentially means that we need to have a sample rate of twice the rate of the smallest changes in a signal. If we do not have this sampling rate then it is possible for us to lose information during the sampling process. 

		\centerimagewide{./images/Nyquist_Example.png}{Here we can see an example of a sample rate on the function $y = sin(4x)$ being insufficient. This sample rate of 1.2 is insufficient for the graph since it's period is $\frac{2\pi}{4} \equiv 1.570$. A sample rate of $\frac{1.570}{2} \equiv 0.785$ is required to be sufficient.}{fig:nyquist_example}

		When measuring air quality we almost certainly will not meet the Nyquist rate and therefore need to compensate. Without any interpolation or extrapolation methods the best we can do is generate data similar to that seen in figure~\ref{fig:stationarypollutantbuildup}. In this figure we see that we only have information where pollutants were measured. In this case it was done with a sensor on a bus and therefore limited to the roads. 

		\centerimagewide{./images/StationaryPollutantBuildUp.png}{A map of air pollution around Edinburgh city centre. Image uses \emph{Open Street Map}.}{fig:stationarypollutantbuildup}

		\centerimage{.5\textwidth}{./images/zurichpm.jpg}{A heatmap of particulate matter in Zurich. The higher pollution levels can clearly be seen to follow transport infrastructure.~\cite{opensensezurich}}{fig:zurichheatmap}

		The solution is to interpolate and extrapolate our data so that what we see in figure~\ref{fig:stationarypollutantbuildup} can be converted into something similar to figure~\ref{fig:zurichheatmap} where we have estimations of pollutant levels in areas where we did not take measurements. 

		With air quality data many institutes and organisations use complex methods of interpolating the data such as \emph{Land Use Regression (LUR)}~\cite{lurtraffic}. LUR and other advanced models~\cite{reviewofaqmodels} have advantages over simple interpolation models in that they can take other information into account. By feeding in information about sources of pollution, terrain, buildings, etc. we can greatly improve the estimations of these models. However, the disadvantage of these models is the complexity. As such it would be useful to determine if simple interpolation algorithms, such as those designed for image or sound processing, are effective at interpolation air quality data sets. The algorithms which will be tested are those discussed in section~\ref{background_interpolation_methods}. These algorithms are: 

		\begin{itemize}
	        \item Bilinear interpolation
	        \item Bicubic interpolation
	        \item Natural neighbour interpolation
	        \item Barnes interpolation
	        \item Nearest neighbour interpolation
	        \item Inverse distance weighting interpolation
	    \end{itemize}

	    The bilinear and bicubic algorithms are generally used for interpolating pixels in images when resized. Natural neighbour, nearest neighbour and inverse distance weighted are more generic interpolation algorithms, and Barnes interpolation has seen application in weather forecasting~\cite{barnesinterpolation}. 



	\section{Methodology}\label{prediction_evaluation_methodology}

		In order to evaluate the efficiency of these algorithms we will employ a simple approach. This approach will use a data set with complimentary values. We will run the data set through the interpolation algorithms and compare the interpolated values to known values from the complimentary data set. The difference between these values will provide a metric as to the accuracy of our interpolation algorithms. 

		\subsection{Data Sets}\label{prediction_evaluation_methodology_data_sets}

			\subsubsection{OpenSense}\label{prediction_evaluation_methodology_data_sets_opensense}
				The first data set, provided by the \emph{OpenSense} group at \emph{ETH Zurich}, provides ozone concentrations based on measurements taken from trams moving around the city of Zurich, Switzerland. This data set only has measurements along the tram tracks. We will perform our interpolation on this data set giving a two dimensional map covering the city of estimated ozone concentrations. We will then use information taken from static sensors, which are not along tram tracks, to measure the accuracy of these interpolation algorithms. 

				\tdi{Put in image of zurich data set here}

				This data set poses certain problems. The main issue is that we only have two static sensors which we can use to determine the accuracy of our algorithms. Ideally we would have many more. Two sensors is enough to show whether some algorithms perform better than others, but only for those points. Their usefulness across an entire city should be reviewed carefully in further experimentation with a more comprehensive data set. A second issue arises from the temporal changes in the data. If we were to take the measurements at any given point in time we would only have as many data points as there are sensors. By selecting a temporal window of measurements we can increase the number of readings we have, which are at different locations due to the motion of the trams, and as such give a denser set of data points to the algorithms, which will allow for more accurate calculations. In taking this temporal window we risk missing out on some information. Should a pollutant change rapidly in the space of a single window, this information would be lost, and may indeed skew our results. Experimentation revealed that a window of 30 minutes is enough to cover as much area as possible, with minimal overlap of tram routes. 


			\subsubsection{Air Quality Scotland}\label{prediction_evaluation_methodology_data_sets_air_quality_scotland}

				The data set from \emph{Air Quality Scotland} is much simpler, and therefore less useful, than the OpenSense data set. This data set consists of eight static air quality monitoring stations across Edinburgh. Out of these eight stations, five form the convex hull of the data set, and one of them is in a high traffic zone. The result of this is that we only have three points which we can use to check our calculations, and one of these is going to have a large discrepancy between the actual values and the estimated values. Furthermore, this data set only has the means at one hour intervals and so the temporal drift mentioned in the above section still applies. However, one advantage that this data set does provide is three different chemical readings to use. 

		\subsection{Data Structure}\label{prediction_evaluation_methodology_data_structure}
			
			In order to use these data sets in the various algorithms we must change the data structure slightly. Two of the algorithms, bilinear interpolation, and bilinear interpolation, work when the data is on a regular grid, which these data sets are not. As such we need to map them onto a regular grid. For the algorithms which are not limited to a grid we do not have to

			With the Zurich data set the area which we are taking measurements from is roughly $5km$ by $5km$. By setting a resolution of 200 by 200 for the grid we can calculate the interpolated values in regions roughly $25m$ by $25m$. Using the same resolution on the Edinburgh data we move our data points from a map of size $15km$ by $9km$ to a grid with cells of size $75m$ by $45m$. 


		

    \section{Results}\label{prediction_evaluation_results}

    	\tdi{Remember, instead of just stating which is better, we need to know if it is good enough}

        \subsection{Nearest Neighbour}\label{prediction_evaluation_results_nearest_neighbour}

        \subsection{Inverse Distance Weighting}\label{prediction_evaluation_results_inverse_distance_weighting}

        \subsection{Bilinear}\label{prediction_evaluation_results_bilinear}

        \subsection{Bicubic}\label{prediction_evaluation_results_bicubic}

        \subsection{Natural Neighbour}\label{prediction_evaluation_results_natural_neighbour}

        \subsection{Barnes}\label{prediction_evaluation_results_barnes}

           
